{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ca899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from utils import *\n",
    "from nn_for_fwi_80_8_attention_3 import UNet_conditional,EMA  #depth=80 channel=8\n",
    "\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "from torch.utils import data\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def gaussian_kernel(size, sigma, num_channels, device):\n",
    "    coords = torch.arange(size, dtype=torch.float32, device=device)\n",
    "    coords -= (size - 1) / 2.0\n",
    "    g = -(coords ** 2) / (2 * sigma ** 2)\n",
    "    g = torch.exp(g)\n",
    "    g /= g.sum()\n",
    "\n",
    "    g_2d = g.unsqueeze(0) * g.unsqueeze(1)\n",
    "    g_2d /= g_2d.sum() \n",
    "\n",
    "    gaussian_filter = g_2d.view(1, 1, size, size).repeat(num_channels, 1, 1, 1)\n",
    "    return gaussian_filter\n",
    "\n",
    "def _ssim(img1, img2, window, data_range, C1, C2):\n",
    "    channels = img1.shape[1]\n",
    "    window = window.to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding='valid', groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding='valid', groups=channels)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding='valid', groups=channels) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding='valid', groups=channels) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding='valid', groups=channels) - mu1_mu2\n",
    "\n",
    "    luminance_map = (2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1).clamp(min=1e-8)\n",
    "    contrast_structure_map = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2).clamp(min=1e-8)\n",
    "    \n",
    "    return luminance_map, contrast_structure_map\n",
    "\n",
    "def msssim(img1, img2, window_size=11, data_range=1.0, size_average=True,\n",
    "           scales=5, weights=None, sigma=1.5):\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError(\"Input images must have the same dimensions.\")\n",
    "    if img1.ndim != 4:\n",
    "        raise ValueError(\"Input images must be 4D tensors (N, C, H, W).\")\n",
    "\n",
    "    num_channels = img1.shape[1]\n",
    "    device = img1.device\n",
    "\n",
    "    if weights is None:\n",
    "        # 默认权重，根据 scales 数量调整\n",
    "        if scales == 5:\n",
    "            weights = [0.0448, 0.2856, 0.3001, 0.2363, 0.1333]\n",
    "        elif scales == 3:\n",
    "            weights = [0.5, 0.3, 0.2] # 示例权重，总和为 1\n",
    "        elif scales == 2: # 为 scales=2 提供一个示例权重\n",
    "            weights = [0.7, 0.3] # 示例：给更精细的尺度更大的权重\n",
    "        elif scales == 1: # 单尺度，权重自然是 1.0\n",
    "            weights = [1.0]\n",
    "        else:\n",
    "            weights = [1.0 / scales] * scales\n",
    "            print(f\"Warning: Using uniform weights for {scales} scales as no specific weights are defined.\")\n",
    "\n",
    "    if len(weights) != scales:\n",
    "        raise ValueError(f\"Number of weights ({len(weights)}) must match number of scales ({scales}).\")\n",
    "    weights = torch.tensor(weights, dtype=torch.float32, device=device).view(1, scales)\n",
    "\n",
    "    C1 = (0.01 * data_range) ** 2\n",
    "    C2 = (0.03 * data_range) ** 2\n",
    "\n",
    "    pad = (window_size - 1) // 2\n",
    "    window = gaussian_kernel(window_size, sigma, num_channels, device)\n",
    "\n",
    "    # 重要的尺寸检查：确保在所有尺度下图像维度都足够大\n",
    "    current_h = img1.shape[2]\n",
    "    current_w = img1.shape[3]\n",
    "    \n",
    "    for i in range(scales):\n",
    "        # reflect padding 要求维度 > pad\n",
    "        if current_h <= pad or current_w <= pad:\n",
    "            raise ValueError(\n",
    "                f\"Image dimension ({current_h}x{current_w}) is too small for \"\n",
    "                f\"reflect padding ({pad}) with window_size={window_size} at scale {i+1}/{scales}. \"\n",
    "                f\"Consider reducing 'scales' or 'window_size', or increasing initial image size.\"\n",
    "            )\n",
    "        current_h //= 2\n",
    "        current_w //= 2\n",
    "            \n",
    "    ssim_components_per_scale = []\n",
    "    \n",
    "    for i in range(scales):\n",
    "        padded_img1 = F.pad(img1, (pad, pad, pad, pad), mode='reflect')\n",
    "        padded_img2 = F.pad(img2, (pad, pad, pad, pad), mode='reflect')\n",
    "\n",
    "        L_map, CS_map = _ssim(padded_img1, padded_img2, window, data_range, C1, C2)\n",
    "        \n",
    "        if i < scales - 1: # 非最粗尺度：使用 CS_map\n",
    "            current_scale_component = CS_map.mean(dim=(-1, -2)).mean(dim=-1)\n",
    "            ssim_components_per_scale.append(current_scale_component)\n",
    "            \n",
    "            img1 = F.avg_pool2d(img1, kernel_size=2, stride=2)\n",
    "            img2 = F.avg_pool2d(img2, kernel_size=2, stride=2)\n",
    "        else: # 最粗尺度：使用 L_map\n",
    "            current_scale_component = L_map.mean(dim=(-1, -2)).mean(dim=-1)\n",
    "            ssim_components_per_scale.append(current_scale_component)\n",
    "\n",
    "    ms_ssim_val = ssim_components_per_scale[-1].pow(weights[0, -1])\n",
    "\n",
    "    for i in range(scales - 1):\n",
    "        ms_ssim_val = ms_ssim_val * ssim_components_per_scale[i].pow(weights[0, i])\n",
    "        \n",
    "    if size_average:\n",
    "        return ms_ssim_val.mean()\n",
    "    else:\n",
    "        return ms_ssim_val\n",
    "\n",
    "class MSSSIMLoss(nn.Module):\n",
    "    def __init__(self, window_size=11, data_range=1.0, size_average=True,\n",
    "                 scales=5, weights=None, sigma=1.5):\n",
    "        super(MSSSIMLoss, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.data_range = data_range\n",
    "        self.size_average = size_average\n",
    "        self.scales = scales\n",
    "        self.weights = weights\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        ms_ssim_val = msssim(img1, img2,\n",
    "                             window_size=self.window_size,\n",
    "                             data_range=self.data_range,\n",
    "                             size_average=self.size_average,\n",
    "                             scales=self.scales,\n",
    "                             weights=self.weights,\n",
    "                             sigma=self.sigma)\n",
    "        return 1.0 - ms_ssim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chang_np_array_size(raw_data,resize_x=224,resize_z=224):\n",
    "    resize = transforms.Resize((resize_x, resize_z))\n",
    "\n",
    "    raw_data_img=Image.fromarray(raw_data)\n",
    "\n",
    "    data_resize=resize(raw_data_img)\n",
    "    data_resize=np.array(data_resize)\n",
    "    return data_resize\n",
    "def get_positional_encoding(seq_len, d_model):\n",
    "    positional_encoding = np.zeros((seq_len, d_model))\n",
    "    for pos in range(seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                        positional_encoding[pos, i] = np.sin(pos / (10000 ** (i / d_model)))\n",
    "                        positional_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((i + 1) / d_model)))\n",
    "    return positional_encoding\n",
    "def make_vp_net(data_raw,n_channel=16):\n",
    "    xn,zn=data_raw.shape\n",
    "    data_net=np.zeros([xn,n_channel,zn])\n",
    "    consecutive_trace=n_channel\n",
    "    for i in range(xn):\n",
    "        try:\n",
    "            if i < int(consecutive_trace/2):\n",
    "        #         for j in range(i):\n",
    "        #             vp_initial[i,j,:]=vp[0,:]\n",
    "                data_net[i,:i,:]=data_raw[:i,:]\n",
    "                data_net[i,i:consecutive_trace-i,:]=data_raw[i:consecutive_trace-i,:]\n",
    "\n",
    "            elif i <= xn -int(consecutive_trace/2) :\n",
    "                data_net[i,:,:]=data_raw[i-int(consecutive_trace/2):i+int(consecutive_trace/2),:]\n",
    "            else:\n",
    "                data_net[i,:,:]=data_raw[xn-consecutive_trace:,:]\n",
    "                data_net[i,consecutive_trace-(xn-i):,:]=data_raw[i:,:]\n",
    "        except:\n",
    "            print(i)\n",
    "    return data_net\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def generate_migrated_data(resize_model, factor=4, fc=0.1):\n",
    "    \"\"\"\n",
    "    Generate migrated seismic data from impedance model using convolution model.\n",
    "    \n",
    "    Parameters:\n",
    "        resize_model (ndarray): 2D impedance model [traces, time_samples]\n",
    "        factor (int): Upsampling factor (default=4)\n",
    "        fc (float): Normalized wavelet frequency [cycles/sample] (default=0.1)\n",
    "    \n",
    "    Returns:\n",
    "        migrated (ndarray): Synthetic seismic section [traces, time_samples]\n",
    "    \"\"\"\n",
    "    # --- 1. Upsample impedance model ---\n",
    "    orig_axis = np.arange(resize_model.shape[1])\n",
    "    new_len = (resize_model.shape[1] - 1) * factor + 1\n",
    "    new_axis = np.linspace(0, resize_model.shape[1]-1, new_len)\n",
    "    \n",
    "    model_up = np.zeros((resize_model.shape[0], new_len))\n",
    "    for i in range(resize_model.shape[0]):\n",
    "        f = interp1d(orig_axis, resize_model[i], kind='linear', \n",
    "                     bounds_error=False, fill_value=\"extrapolate\")\n",
    "        model_up[i] = f(new_axis)\n",
    "\n",
    "    # --- 2. Calculate reflectivities ---\n",
    "    num = model_up[:, 1:] - model_up[:, :-1]\n",
    "    den = model_up[:, 1:] + model_up[:, :-1]\n",
    "    eps = 1e-9\n",
    "    den = np.where(np.abs(den) < eps, eps, den)\n",
    "    refl = num / den  # [traces, new_len-1]\n",
    "\n",
    "    # --- 3. Build reflectivity series ---\n",
    "    refl_series = np.zeros_like(model_up)\n",
    "    refl_series[:, 1:] = refl\n",
    "\n",
    "    # --- 4. Generate Ricker wavelet ---\n",
    "    # Original domain wavelet (51 samples)\n",
    "    wv_len_orig = 51\n",
    "    center = (wv_len_orig-1)//2\n",
    "    t_orig = np.arange(wv_len_orig) - center\n",
    "    wavelet_orig = (1 - 2*(np.pi*fc*t_orig)**2) * np.exp(-(np.pi*fc*t_orig)**2)\n",
    "    \n",
    "    # Upsampled wavelet\n",
    "    wv_up_axis = np.linspace(0, wv_len_orig-1, (wv_len_orig-1)*factor + 1)\n",
    "    f_wavelet = interp1d(np.arange(wv_len_orig), wavelet_orig, \n",
    "                         kind='linear', bounds_error=False, fill_value=0)\n",
    "    wavelet_up = f_wavelet(wv_up_axis)\n",
    "    wavelet_up /= np.max(np.abs(wavelet_up))  # Normalize\n",
    "\n",
    "    # --- 5. Convolve with wavelet ---\n",
    "    synthetic = np.zeros_like(model_up)\n",
    "    for i in range(model_up.shape[0]):\n",
    "        synthetic[i] = np.convolve(refl_series[i], wavelet_up, mode='same')\n",
    "\n",
    "    # --- 6. Downsample to original resolution ---\n",
    "    migrated = np.zeros_like(resize_model)\n",
    "    for i in range(synthetic.shape[0]):\n",
    "        f = interp1d(new_axis, synthetic[i], kind='linear', \n",
    "                     bounds_error=False, fill_value=\"extrapolate\")\n",
    "        migrated[i] = f(orig_axis)\n",
    "    \n",
    "    return migrated\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def multi_migrated_data_cuda(impedance_model_3d, factor=4, fc=0.1, device='cuda'):\n",
    "    image_3d_cuda = torch.zeros_like(impedance_model_3d, device=device)\n",
    "    for i in range(impedance_model_3d.shape[0]):\n",
    "        image_3d_cuda[i]=generate_migrated_data_cuda(impedance_model_3d[i], factor=factor, fc=fc)\n",
    "    return image_3d_cuda\n",
    "        \n",
    "\n",
    "\n",
    "def generate_migrated_data_cuda(impedance_model, factor=4, fc=0.1, device='cuda'):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate migrated seismic data using a convolution model and a Ricker wavelet,\n",
    "    with upsampling via `torch.nn.functional.interpolate`.\n",
    "    \n",
    "    Parameters:\n",
    "        impedance_model (ndarray or tensor): 2D impedance model [traces, time_samples]\n",
    "        factor (int): Upsampling factor (default=4)\n",
    "        fc (float): Normalized central frequency of the Ricker wavelet [cycles/sample] (default=0.1)\n",
    "        device (str): 'cuda' for GPU or 'cpu' for CPU (default='cuda')\n",
    "    \n",
    "    Returns:\n",
    "        migrated (tensor): Synthetic seismic section [traces, time_samples]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert input impedance model to torch tensor\n",
    "    impedance_model = torch.tensor(impedance_model, dtype=torch.float32, device=device)\n",
    "\n",
    "    # --- 1. Upsample impedance model ---\n",
    "    orig_axis = torch.arange(impedance_model.shape[1], device=device).float().unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, original_length)\n",
    "    new_len = (impedance_model.shape[1] - 1) * factor + 1\n",
    "    new_axis = torch.linspace(0, impedance_model.shape[1] - 1, new_len, device=device).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, new_length)\n",
    "\n",
    "    # Reshape impedance model to (batch_size, channels, length) for interpolation\n",
    "    impedance_model_reshaped = impedance_model.unsqueeze(1)  # Shape: (traces, 1, time_samples)\n",
    "\n",
    "    # Interpolate (upsample) the impedance model\n",
    "    model_up = F.interpolate(impedance_model_reshaped, size=new_len, mode='linear', align_corners=True)\n",
    "\n",
    "    # --- 2. Calculate reflectivities ---\n",
    "    num = model_up[:, :, 1:] - model_up[:, :, :-1]\n",
    "    den = model_up[:, :, 1:] + model_up[:, :, :-1]\n",
    "    eps = 1e-9\n",
    "    den = torch.where(torch.abs(den) < eps, eps, den)  # Avoid division by zero\n",
    "    refl = num / den  # [traces, new_len-1]\n",
    "\n",
    "    # --- 3. Build reflectivity series ---\n",
    "    refl_series = torch.zeros_like(model_up)\n",
    "    refl_series[:, :, 1:] = refl\n",
    "\n",
    "    # --- 4. Generate Ricker wavelet ---\n",
    "    wv_len_orig = 51\n",
    "    center = (wv_len_orig - 1) // 2\n",
    "    t_orig = torch.arange(wv_len_orig, device=device) - center\n",
    "    wavelet_orig = (1 - 2 * (torch.pi * fc * t_orig) ** 2) * torch.exp(-(torch.pi * fc * t_orig) ** 2)\n",
    "\n",
    "    # Upsampled wavelet using interpolation\n",
    "    # Ensure wavelet is a 3D tensor: (1, 1, length)\n",
    "    wavelet_orig = wavelet_orig.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, length)\n",
    "#     print(wavelet_orig.shape,'wavelet_orig')\n",
    "    wv_up_axis = torch.linspace(0, wv_len_orig - 1, (wv_len_orig - 1) * factor + 1, device=device).unsqueeze(0).unsqueeze(0)\n",
    "    wavelet_up = F.interpolate(wavelet_orig, size=wv_up_axis.shape[-1], mode='linear', align_corners=True).squeeze(0).squeeze(0)\n",
    "\n",
    "    wavelet_up = wavelet_up / torch.max(torch.abs(wavelet_up))  # Normalize wavelet\n",
    "\n",
    "    # --- 5. Convolve with wavelet ---\n",
    "    synthetic = torch.zeros_like(model_up, device=device)\n",
    "    \n",
    "    # Make sure the wavelet is in the correct shape for conv1d\n",
    "    wavelet_up = wavelet_up.unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, kernel_size)\n",
    "\n",
    "    for i in range(model_up.shape[0]):\n",
    "        synthetic[i] = F.conv1d(refl_series[i].unsqueeze(0), wavelet_up, padding='same').squeeze(0)\n",
    "\n",
    "    # --- 6. Downsample to original resolution ---\n",
    "    migrated = torch.zeros_like(impedance_model, device=device)\n",
    "    for i in range(synthetic.shape[0]):\n",
    "        # Ensure the correct shape for interpolation (3D tensor: (1, 1, length))\n",
    "        synthetic_i = synthetic[i].unsqueeze(0)  # Shape: (1, 1, length)\n",
    "        # Now we can use F.interpolate\n",
    "#         print(synthetic_i.shape,'synthetic_i')\n",
    "\n",
    "        migrated[i] = F.interpolate(synthetic_i, size=impedance_model.shape[1], mode='linear', align_corners=True).squeeze(0).squeeze(0)\n",
    "\n",
    "    return migrated\n",
    "\n",
    "\n",
    "# fc is cycle per sample  e.g. 0.1 means the full cycle of the wavelet need 10 grid, and that means the wavenumber of  the wavelet is 10 grid *20m grid size=200m, so the freq =velocity 2000m/s/ wavenumber 200m  = 10 hz\n",
    "# true freq = velocity/(grid_size/fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1450b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RFlow:\n",
    "    def __init__(self, step=20,img_size=160, device=device):\n",
    "        self.step = step\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def euler(self, x_t, v, dt):\n",
    "        \"\"\" 使用欧拉方法计算下一个时间步长的值\n",
    "            \n",
    "        Args:\n",
    "            x_t: 当前的值，维度为 [B, C, H, W]\n",
    "            v: 当前的速度，维度为 [B, C, H, W]\n",
    "            dt: 时间步长\n",
    "        \"\"\"\n",
    "        x_t = x_t + v * dt\n",
    "\n",
    "        return x_t\n",
    "\n",
    "    # 路线\n",
    "    # v1.2: reflow增加x_0的输入\n",
    "    def create_flow(self, x_1, t, x_0=None):\n",
    "        \"\"\" 使用x_t = t * x_1 + (1 - t) * x_0公式构建x_0到x_1的流\n",
    "\n",
    "            X_1是原始图像 X_0是噪声图像（服从标准高斯分布）\n",
    "            \n",
    "        Args:\n",
    "            x_1: 原始图像，维度为 [B, C, H, W]\n",
    "            t: 一个标量，表示时间，时间范围为 [0, 1]，维度为 [B]\n",
    "            x_0: 噪声图像，维度为 [B, C, H, W]，默认值为None\n",
    "            \n",
    "        Returns:\n",
    "            x_t: 在时间t的图像，维度为 [B, C, H, W]\n",
    "            x_0: 噪声图像，维度为 [B, C, H, W]\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # 需要一个x0，x0服从高斯噪声\n",
    "        if x_0 is None:\n",
    "            x_0 = torch.randn_like(x_1).to(self.device)\n",
    "\n",
    "        t = t[:, None, None, None].to(self.device)  # [B, 1, 1, 1]\n",
    "\n",
    "        # 获得xt的值\n",
    "        x_t = t * x_1 + (1 - t) * x_0\n",
    "\n",
    "        return x_t, x_0\n",
    "\n",
    "    # 司机\n",
    "    def mse_loss(self, v, x_1, x_0):\n",
    "        \"\"\" 计算RectifiedFlow的损失函数\n",
    "        L = MSE(x_1 - x_0 - v(t))  匀速直线运动\n",
    "\n",
    "        Args:\n",
    "            v: 速度，维度为 [B, C, H, W]\n",
    "            x_1: 原始图像，维度为 [B, C, H, W]\n",
    "            x_0: 噪声图像，维度为 [B, C, H, W]\n",
    "        \"\"\"\n",
    "\n",
    "        # 求loss函数，是一个MSE，最后维度是[B]\n",
    "\n",
    "        loss = F.mse_loss(x_1 - x_0, v)\n",
    "        # loss = torch.mean((x_1 - x_0 - v)**2)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def sample_for_gen(self,model=None,n=5,\n",
    "        y=None,z=None,w=None,n_channel=None,\n",
    "        cfg_scale=7.0,\n",
    "        save_path='./results',\n",
    "        save_noise_path=None,\n",
    "        device='cuda'):\n",
    "        \n",
    "        \"\"\"flow matching模型推理\n",
    "\n",
    "        Args:\n",
    "            checkpoint_path (str): 模型路径\n",
    "            base_channels (int, optional): MiniUnet的基础通道数，默认值为16。\n",
    "            step (int, optional): 采样步数（Euler方法的迭代次数），默认值为50。\n",
    "            num_imgs (int, optional): 推理一次生成图片数量，默认值为5。\n",
    "            y (torch.Tensor, optional): 条件生成中的条件，可以为数据标签（每一个标签是一个类别int型）或text文本（下一版本支持）,维度为[B]或[B, L]，其中B要么与num_imgs相等，要么为1（所有图像依照同一个条件生成）。 \n",
    "            cfg_scale (float, optional): Classifier-free Guidance的缩放因子，默认值为7.0，y如果是None，无论这个值是几都是无条件生成。这个值越大，多样性下降，但生成图像更符合条件要求。这个值越小，多样性增加，但生成图像可能不符合条件要求。\n",
    "            save_path (str, optional): 保存路径，默认值为'./results'。\n",
    "            save_noise_path (str, optional): 保存噪声路径，默认值为None。\n",
    "            device (str, optional): 推理设备，默认值为'cuda'。\n",
    "        \"\"\"\n",
    "\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        if save_noise_path is not None:\n",
    "            os.makedirs(save_noise_path, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "        # 无条件或有条件生成图片\n",
    "#                 print(f'Generating {i}th image...')\n",
    "                # Euler法间隔\n",
    "                dt = 1.0 / self.step\n",
    "\n",
    "                # 初始的x_t就是x_0，标准高斯噪声\n",
    "                x_t = torch.randn((n, 2, n_channel, self.img_size)).to(self.device)\n",
    "                noise = x_t.detach().cpu().numpy()\n",
    "\n",
    "                # 提取第i个图像的标签条件y_i\n",
    "#                 if y is not None:\n",
    "#                     y_i = y.unsqueeze(0)\n",
    "                y_i = y.to(device)\n",
    "                z_i = z.to(device)\n",
    "                w_i = w.to(device)\n",
    "\n",
    "                for j in range(self.step):\n",
    "#                     if j % 10 == 0:\n",
    "#                         print(f'Generating {i}th image, step {j}...')\n",
    "                    t = torch.ones(n)*j * dt\n",
    "                    t = t.to(device)\n",
    "\n",
    "                    \n",
    "                    v_pred = model(x=x_t, t=t, y=y_i,z=z_i,w=w_i)\n",
    "        \n",
    "            \n",
    "                    # 使用Euler法计算下一个时间的x_t\n",
    "                    x_t = rf.euler(x_t, v_pred, dt)\n",
    "\n",
    "                # 最后一步的x_t就是生成的图片\n",
    "                # 先去掉batch维度\n",
    "    #             x_t = x_t[0]\n",
    "        return x_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NZ=200\n",
    "NX=70\n",
    "n_cmp_raw = 2\n",
    "NR=200\n",
    "Tn = 1500  # 时间长度\n",
    "# n_channel=16\n",
    "# n_channel_raw = 16\n",
    "\n",
    "n_channel=8\n",
    "n_channel_raw = 8  #{}_cmp_2\n",
    "\n",
    "n_cmp=2\n",
    "DX=20\n",
    "# wavelet_freq=30\n",
    "\n",
    "pao_interval=5\n",
    "\n",
    "dt=0.002\n",
    "\n",
    "\n",
    "# smooth_sigma=3\n",
    "smooth_sigma=5\n",
    "\n",
    "wavelet_freq=30\n",
    "migrate_factor=4\n",
    "\n",
    "\n",
    "nz=NZ\n",
    "img_size=64\n",
    "\n",
    "root_dir='/data/wsl/model_openfwi/'\n",
    "\n",
    "import scipy.ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "iter_i=200\n",
    "\n",
    "\n",
    "\n",
    "def make_model_big(model_0,resize_x=100,resize_z=140):\n",
    "    vp_i_reshape2 = ndimage.zoom(model_0, 3, order=4)  # order=3为双三次插值\n",
    "    vp_i_reshape=chang_np_array_size(vp_i_reshape2,resize_x=resize_x,resize_z=resize_z)\n",
    "    smoothed = anisotropic_diffusion(vp_i_reshape, kappa=30, iterations=15)\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vp_arr=[]\n",
    "rtm_arr=[]\n",
    "cmp_arr=[]\n",
    "rtm0_arr=[]\n",
    "vp0_arr=[]\n",
    "    \n",
    "\n",
    "root_dir='/data/wsl/model_openfwi/'\n",
    "model_dir=root_dir+'flatfault/model_200_70/'\n",
    "for iter_i in range(0,800,1):\n",
    "    cmp_dir=root_dir+'flatfault/cmp_data_200_70_add_layer/{}_cmp/'.format(iter_i)\n",
    "    vp_real_i0 = np.fromfile(model_dir+\"model{}.bin\".format(iter_i), dtype=np.float32).reshape([NZ, NX])\n",
    "    \n",
    "    vp_real_i0=chang_np_array_size(vp_real_i0,resize_x=NZ,resize_z=img_size)\n",
    "\n",
    "    vp_real_i=scipy.ndimage.filters.gaussian_filter(vp_real_i0, sigma=smooth_sigma)\n",
    "    vp_net_i0=make_vp_net(vp_real_i0,n_channel=n_channel)\n",
    "#     rtm_i= 2 * (vp_real_i0 - vp_real_i) / vp_real_i\n",
    "    vp_net_i=make_vp_net(vp_real_i,n_channel=n_channel)\n",
    "\n",
    "\n",
    "    cmp_i=np.fromfile(cmp_dir+\"cmp_{}_{}_{}.bin\".format(NZ,n_channel_raw * n_cmp_raw,Tn), dtype=np.float32).reshape(NZ, n_channel_raw * n_cmp_raw, Tn )\n",
    "    \n",
    "\n",
    "        \n",
    "    \"\"\"============================================\"\"\"\n",
    "    max_vp_top_layer=vp_real_i0[int(NZ/2),0]\n",
    "    mean_vp_all_layer=np.mean(vp_real_i0[:,:])   \n",
    "       \n",
    "    dx_2=2*DX*20*3  \n",
    "    t_path_2=dx_2/max_vp_top_layer\n",
    "    last_T=(4.3*(NX+20)*DX)/mean_vp_all_layer\n",
    "    time_cut_arrival=int(t_path_2/dt)\n",
    "    last_time=int(1/dt+last_T/dt)\n",
    "    \"\"\"============================================\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    cmp_net_i=np.zeros([NZ,n_channel_raw * n_cmp_raw,500])\n",
    "\n",
    "\n",
    "    for channel_i in range(n_channel_raw * n_cmp_raw):\n",
    "        cmp_net_i[:,channel_i,:]=chang_np_array_size(cmp_i[:,channel_i,time_cut_arrival:time_cut_arrival+last_time],resize_x=NZ,resize_z=500)\n",
    "\n",
    "    \n",
    "    dt=6e-3\n",
    "    f_low=2\n",
    "    N_filter=2\n",
    "    import scipy.signal\n",
    "    aa, bb = scipy.signal.butter(N_filter, 2 * f_low / (1 / dt), btype='highpass',analog=False, output='ba',fs=None)  # low_freq/ Nyquist freq == low_freq/（dt/2）\n",
    "    cmp_i_resize_filter_t = scipy.signal.filtfilt(aa, bb, cmp_net_i)\n",
    "    cmp_net_i=cmp_i_resize_filter_t\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    resize_model=vp_real_i0\n",
    "\n",
    "\n",
    "    rtm_i = generate_migrated_data(resize_model, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))# true freq = velocity/(grid_size/fc) 调节最后一个数字为 freq 目前是30hz\n",
    "\n",
    "    rtm_i=chang_np_array_size(rtm_i,resize_x=NZ,resize_z=img_size)\n",
    "\n",
    "    rtm_net_i=make_vp_net(rtm_i,n_channel=n_channel)\n",
    "    \n",
    "    \n",
    "    rtm_i0 = generate_migrated_data(vp_real_i, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))# true freq = velocity/(grid_size/fc) 调节最后一个数字为 freq 目前是30hz\n",
    "\n",
    "    rtm_i0=chang_np_array_size(rtm_i0,resize_x=NZ,resize_z=img_size)\n",
    "\n",
    "    rtm_net_i0=make_vp_net(rtm_i0,n_channel=n_channel)\n",
    "    rtm0_arr.append(rtm_net_i0[int(n_channel/2):-int(n_channel/2)])\n",
    "\n",
    "    vp_arr.append(vp_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    rtm_arr.append(rtm_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    cmp_arr.append(cmp_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    vp0_arr.append(vp_net_i0[int(n_channel/2):-int(n_channel/2)])\n",
    "    \n",
    "model_dir=root_dir+'curvevelB/model_200_70/'\n",
    "for iter_i in range(0,400,1):\n",
    "    cmp_dir=root_dir+'curvevelB/cmp_data_200_70_add_layer/{}_cmp/'.format(iter_i)\n",
    "    vp_real_i0 = np.fromfile(model_dir+\"model{}.bin\".format(iter_i), dtype=np.float32).reshape([NZ, NX])\n",
    "    vp_real_i0=chang_np_array_size(vp_real_i0,resize_x=NZ,resize_z=img_size)\n",
    "\n",
    "    vp_real_i=scipy.ndimage.filters.gaussian_filter(vp_real_i0, sigma=smooth_sigma)\n",
    "    vp_net_i0=make_vp_net(vp_real_i0,n_channel=n_channel)\n",
    "#     rtm_i= 2 * (vp_real_i0 - vp_real_i) / vp_real_i\n",
    "    vp_net_i=make_vp_net(vp_real_i,n_channel=n_channel)\n",
    "\n",
    "\n",
    "    cmp_i=np.fromfile(cmp_dir+\"cmp_{}_{}_{}.bin\".format(NZ,n_channel_raw * n_cmp_raw,Tn), dtype=np.float32).reshape(NZ, n_channel_raw * n_cmp_raw, Tn )\n",
    "\n",
    "    \n",
    "        \n",
    "    \"\"\"============================================\"\"\"\n",
    "    max_vp_top_layer=vp_real_i0[int(NZ/2),0]\n",
    "    mean_vp_all_layer=np.mean(vp_real_i0[:,:])   # 看最小频率 这里就看 主频的 4\n",
    "       \n",
    "    dx_2=2*DX*20*3  #20是顶层厚度  共覆盖点为2的时候 斜路径 2 是 双倍程\n",
    "    t_path_2=dx_2/max_vp_top_layer\n",
    "    last_T=(4.3*(NX+20)*DX)/mean_vp_all_layer\n",
    "    time_cut_arrival=int(t_path_2/dt)\n",
    "    last_time=int(1/dt+last_T/dt)\n",
    "    \"\"\"============================================\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    cmp_net_i=np.zeros([NZ,n_channel_raw * n_cmp_raw,500])\n",
    "\n",
    "\n",
    "    for channel_i in range(n_channel_raw * n_cmp_raw):\n",
    "        cmp_net_i[:,channel_i,:]=chang_np_array_size(cmp_i[:,channel_i,time_cut_arrival:time_cut_arrival+last_time],resize_x=NZ,resize_z=500)\n",
    "\n",
    "    \n",
    "    dt=6e-3\n",
    "    f_low=2\n",
    "    N_filter=2\n",
    "    import scipy.signal\n",
    "    aa, bb = scipy.signal.butter(N_filter, 2 * f_low / (1 / dt), btype='highpass',analog=False, output='ba',fs=None)  # low_freq/ Nyquist freq == low_freq/（dt/2）\n",
    "    cmp_i_resize_filter_t = scipy.signal.filtfilt(aa, bb, cmp_net_i)\n",
    "    cmp_net_i=cmp_i_resize_filter_t\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    resize_model=vp_real_i0\n",
    "\n",
    "\n",
    "    rtm_i = generate_migrated_data(resize_model, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))# true freq = velocity/(grid_size/fc) 调节最后一个数字为 freq 目前是30hz\n",
    "    rtm_i=chang_np_array_size(rtm_i,resize_x=NZ,resize_z=img_size)\n",
    "    rtm_net_i=make_vp_net(rtm_i,n_channel=n_channel)\n",
    "    \n",
    "    \n",
    "    rtm_i0 = generate_migrated_data(vp_real_i, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))# true freq = velocity/(grid_size/fc) 调节最后一个数字为 freq 目前是30hz\n",
    "    rtm_i0=chang_np_array_size(rtm_i0,resize_x=NZ,resize_z=img_size)\n",
    "    rtm_net_i0=make_vp_net(rtm_i0,n_channel=n_channel)\n",
    "    \n",
    "    rtm0_arr.append(rtm_net_i0[int(n_channel/2):-int(n_channel/2)])\n",
    "\n",
    "    vp_arr.append(vp_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    rtm_arr.append(rtm_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    cmp_arr.append(cmp_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    vp0_arr.append(vp_net_i0[int(n_channel/2):-int(n_channel/2)])\n",
    "\n",
    "    \n",
    "model_dir=root_dir+'flat_b/model_200_70/'\n",
    "for iter_i in range(0,200,1):\n",
    "    cmp_dir=root_dir+'flat_b/cmp_data_200_70_add_layer/{}_cmp/'.format(iter_i)\n",
    "    vp_real_i0 = np.fromfile(model_dir+\"model{}.bin\".format(iter_i), dtype=np.float32).reshape([NZ, NX])\n",
    "    vp_real_i0=chang_np_array_size(vp_real_i0,resize_x=NZ,resize_z=img_size)\n",
    "\n",
    "    vp_real_i=scipy.ndimage.filters.gaussian_filter(vp_real_i0, sigma=smooth_sigma)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    vp_net_i0=make_vp_net(vp_real_i0,n_channel=n_channel)\n",
    "\n",
    "    vp_net_i=make_vp_net(vp_real_i,n_channel=n_channel)\n",
    "\n",
    "\n",
    "    cmp_i=np.fromfile(cmp_dir+\"cmp_{}_{}_{}.bin\".format(NZ,n_channel_raw * n_cmp_raw,Tn), dtype=np.float32).reshape(NZ, n_channel_raw * n_cmp_raw, Tn )\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    \"\"\"============================================\"\"\"\n",
    "    max_vp_top_layer=vp_real_i0[int(NZ/2),0]\n",
    "    mean_vp_all_layer=np.mean(vp_real_i0[:,:])   # 看最小频率 这里就看 主频的 4\n",
    "       \n",
    "    dx_2=2*DX*20*3  #20是顶层厚度  共覆盖点为2的时候 斜路径 2 是 双倍程\n",
    "    t_path_2=dx_2/max_vp_top_layer\n",
    "    last_T=(4.3*(NX+20)*DX)/mean_vp_all_layer\n",
    "    time_cut_arrival=int(t_path_2/dt)\n",
    "    last_time=int(1/dt+last_T/dt)\n",
    "    \"\"\"============================================\"\"\"\n",
    "    \n",
    "    cmp_net_i=np.zeros([NZ,n_channel_raw * n_cmp_raw,500])\n",
    "\n",
    "\n",
    "    for channel_i in range(n_channel_raw * n_cmp_raw):\n",
    "        cmp_net_i[:,channel_i,:]=chang_np_array_size(cmp_i[:,channel_i,time_cut_arrival:time_cut_arrival+last_time],resize_x=NZ,resize_z=500)\n",
    "\n",
    "    dt=6e-3\n",
    "    f_low=2\n",
    "    N_filter=2\n",
    "    import scipy.signal\n",
    "    aa, bb = scipy.signal.butter(N_filter, 2 * f_low / (1 / dt), btype='highpass',analog=False, output='ba',fs=None)  # low_freq/ Nyquist freq == low_freq/（dt/2）\n",
    "    cmp_i_resize_filter_t = scipy.signal.filtfilt(aa, bb, cmp_net_i)\n",
    "    cmp_net_i=cmp_i_resize_filter_t\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    resize_model=vp_real_i0\n",
    "    rtm_i = generate_migrated_data(resize_model, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))# true freq = velocity/(grid_size/fc) 调节最后一个数字为 freq 目前是30hz\n",
    "    rtm_i=chang_np_array_size(rtm_i,resize_x=NZ,resize_z=img_size)\n",
    "    rtm_net_i=make_vp_net(rtm_i,n_channel=n_channel)\n",
    "    \n",
    "    \n",
    "    rtm_i0 = generate_migrated_data(vp_real_i, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))# true freq = velocity/(grid_size/fc) 调节最后一个数字为 freq 目前是30hz\n",
    "    rtm_i0=chang_np_array_size(rtm_i0,resize_x=NZ,resize_z=img_size)\n",
    "    rtm_net_i0=make_vp_net(rtm_i0,n_channel=n_channel)\n",
    "    rtm0_arr.append(rtm_net_i0[int(n_channel/2):-int(n_channel/2)])\n",
    "    \n",
    "\n",
    "    vp_arr.append(vp_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    rtm_arr.append(rtm_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    cmp_arr.append(cmp_net_i[int(n_channel/2):-int(n_channel/2)])\n",
    "    vp0_arr.append(vp_net_i0[int(n_channel/2):-int(n_channel/2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b929a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_arr=np.array(vp_arr)\n",
    "rtm_arr=np.array(rtm_arr)\n",
    "cmp_arr=np.array(cmp_arr)\n",
    "rtm0_arr=np.array(rtm0_arr)\n",
    "vp0_arr=np.array(vp0_arr)\n",
    "\n",
    "vp0_arr=np.concatenate(vp0_arr,axis=0)\n",
    "vp_arr=np.concatenate(vp_arr,axis=0)\n",
    "rtm_arr=np.concatenate(rtm_arr,axis=0)\n",
    "cmp_arr=np.concatenate(cmp_arr,axis=0)\n",
    "rtm0_arr=np.concatenate(rtm0_arr,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "vp_mean = np.mean(vp_arr,axis=(0,-1), keepdims=True)\n",
    "vp_std = np.std(vp_arr,axis=(0,-1), keepdims=True)\n",
    "vp_arr = (vp_arr - vp_mean) / (vp_std+1e-12)\n",
    "\n",
    "vp0_mean = np.mean(vp0_arr,axis=(0,-1), keepdims=True)\n",
    "vp0_std = np.std(vp0_arr,axis=(0,-1), keepdims=True)\n",
    "vp0_arr = (vp0_arr - vp0_mean) / (vp0_std+1e-12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cmp_mean = np.mean(cmp_arr,axis=(0,-1), keepdims=True)\n",
    "cmp_std = np.std(cmp_arr,axis=(0,-1), keepdims=True)\n",
    "cmp_arr = (cmp_arr - cmp_mean) / (cmp_std+1e-12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rtm_mean = np.mean(rtm_arr,axis=(0,-1), keepdims=True)\n",
    "rtm_std = np.std(rtm_arr,axis=(0,-1), keepdims=True)\n",
    "rtm_net = (rtm_arr - rtm_mean) / (rtm_std+1e-12)\n",
    "\n",
    "rtm0_mean = np.mean(rtm0_arr,axis=(0,-1), keepdims=True)\n",
    "rtm0_std = np.std(rtm0_arr,axis=(0,-1), keepdims=True)\n",
    "rtm0_net = (rtm0_arr - rtm0_mean) / (rtm0_std+1e-12)\n",
    "\n",
    "# np.save(root_dir+\"rtm0_mean{}.npy\".format(smooth_sigma),rtm0_mean)\n",
    "# np.save(root_dir+\"rtm0_std{}.npy\".format(smooth_sigma),rtm0_std)\n",
    "# np.save(root_dir+\"rtm_mean{}.npy\".format(smooth_sigma),rtm_mean)\n",
    "# np.save(root_dir+\"rtm_std{}.npy\".format(smooth_sigma),rtm_std)\n",
    "# np.save(root_dir+\"vp0_mean{}.npy\".format(smooth_sigma),vp0_mean)\n",
    "# np.save(root_dir+\"vp0_std{}.npy\".format(smooth_sigma),vp0_std)\n",
    "# np.save(root_dir+\"vp_mean{}.npy\".format(smooth_sigma),vp_mean)\n",
    "# np.save(root_dir+\"vp_std{}.npy\".format(smooth_sigma),vp_std)\n",
    "# np.save(root_dir+\"cmp_mean{}.npy\".format(smooth_sigma),cmp_mean)\n",
    "# np.save(root_dir+\"cmp_std{}.npy\".format(smooth_sigma),cmp_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243141b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NR=vp_arr.shape[0]\n",
    "\n",
    "\n",
    "resize_x=n_channel*n_cmp\n",
    "resize_z=256\n",
    "\n",
    "\n",
    "    \n",
    "resized_seismic_data=np.zeros([NR,3,resize_x,resize_z]) # 0:cmp 1:vel_smooth\n",
    "for i in range(NR):\n",
    "    resized_seismic_data[i,0]=chang_np_array_size(cmp_arr[i],resize_x=int(resize_x),resize_z=resize_z)\n",
    "    resized_seismic_data[i,1]=chang_np_array_size(vp_arr[i],resize_x=int(resize_x),resize_z=resize_z)    \n",
    "    resized_seismic_data[i,2]=chang_np_array_size(rtm0_net[i],resize_x=int(resize_x),resize_z=resize_z)  \n",
    "\n",
    "\n",
    "\n",
    "nx=NR\n",
    "print(nx)\n",
    "\n",
    "\n",
    "\n",
    "input_data=np.zeros([nx,2,n_channel,img_size])\n",
    "input_data[:,0]=rtm_net.reshape([nx,n_channel,img_size])\n",
    "input_data[:,1]=vp0_arr.reshape([nx,n_channel,img_size])\n",
    "\n",
    "\n",
    "\n",
    "np.save(root_dir+\"cmp_vp0_rtm0_sigma{}.npy\".format(smooth_sigma),resized_seismic_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(input_data.shape)\n",
    "print(resized_seismic_data.shape)\n",
    "\n",
    "\n",
    "NR=input_data.shape[0]\n",
    "nx=NR\n",
    "\n",
    "resize_x=n_channel*n_cmp\n",
    "resize_z=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e0384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbbd92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd865b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp0_mean_cuda=torch.tensor(vp0_mean).float().cuda()\n",
    "vp0_std_cuda=torch.tensor(vp0_std).float().cuda()\n",
    "\n",
    "rtm_mean_cuda=torch.tensor(rtm_mean).float().cuda()\n",
    "rtm_std_cuda=torch.tensor(rtm_std).float().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ff4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f52de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 400\n",
    "image_size = img_size\n",
    "device = \"cuda\"\n",
    "# args.device = \"cpu\"\n",
    "\n",
    "lr = 3e-4\n",
    "run_name = \"SAVE_DIRS\".format(wavelet_freq,smooth_sigma) \n",
    "\n",
    "\n",
    "# \n",
    "setup_logging(run_name)\n",
    "device = device\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = UNet_conditional(c_in=2, c_out=2,number_traces=resize_x).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "rtm_min=np.mean(np.abs(input_data[:,0]))\n",
    "vp_min=np.mean(np.abs(input_data[:,1]))\n",
    "# \n",
    "ms_ssim_loss_fn_rtm = MSSSIMLoss(data_range=rtm_min, scales=1).to(device) # 图像在 [0, 1] 范围内\n",
    "\n",
    "ms_ssim_loss_fn_vp = MSSSIMLoss(data_range=vp_min, scales=1).to(device) # 图像在 [0, 1] 范围内\n",
    "\n",
    "\n",
    "\n",
    "rf = RFlow(step=20,img_size=image_size, device=device)\n",
    "\n",
    "\n",
    "\n",
    "logger = SummaryWriter(os.path.join(\"runs\", run_name))\n",
    "l = nx\n",
    "ema = EMA(0.995)\n",
    "ema_model = copy.deepcopy(model).eval().requires_grad_(False)\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "lr_adjust_epoch=500\n",
    "scheduler = StepLR(optimizer, step_size=lr_adjust_epoch, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "\n",
    "train_rtm_data=torch.tensor(input_data).float()\n",
    "train_seismic_data=torch.tensor(resized_seismic_data).float()\n",
    "loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82587f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 300\n",
    "dataloader = data.DataLoader(\n",
    "    data.TensorDataset(train_rtm_data,train_seismic_data[:,0],train_seismic_data[:,1],train_seismic_data[:,2]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True       # 启用锁页内存加速传输\n",
    ")\n",
    "###条件也可以逐层➕ 比如t<5时 只加浅层的，深度随时间慢慢增加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_seismic_data=torch.tensor(resized_seismic_data).float()\n",
    "\n",
    "early_stop_patience = 100  # 容忍的连续无改善epoch数\n",
    "early_stop_delta = 0.000000001  # 视为有改善的最小变化阈值\n",
    "best_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "accumulation_steps = 10\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for i,(images_raw,labels1,labels2,labels3) in enumerate(dataloader):\n",
    "\n",
    "\n",
    "        images = images_raw.to(device, non_blocking=True)\n",
    "        labels1=labels1.to(device, non_blocking=True)\n",
    "        labels2=labels2.to(device, non_blocking=True)\n",
    "        labels3=labels3.to(device, non_blocking=True)\n",
    "\n",
    "        t = torch.rand(images.size(0)).to(device, non_blocking=True)\n",
    "        x_t, x_0 = rf.create_flow(x_1=images, t=t)\n",
    "\n",
    "        if np.random.random() < 0.2:\n",
    "            labels1 = None\n",
    "            labels2 = None\n",
    "            labels3 = None\n",
    "\n",
    "        v_pred = model(x_t, t, labels1,labels2,labels3)\n",
    "        \n",
    "#         print(v_pred.shape)\n",
    "        indices = torch.nonzero(t >= 0.4).squeeze()\n",
    "#         print(indices.shape)\n",
    "        if indices is not None:\n",
    "            rtm_from_pred_cuda=multi_migrated_data_cuda(v_pred[indices,1]*(vp0_std_cuda+1e-12)+vp0_mean_cuda, factor=migrate_factor, fc=(DX/(3000/wavelet_freq)))\n",
    "    #         print(rtm_from_pred_cuda.shape)\n",
    "            rtm_from_pred_cuda=(rtm_from_pred_cuda-rtm_mean_cuda)/(rtm_std_cuda+1e-12)\n",
    "\n",
    "            loss2_1=mse(rtm_from_pred_cuda,v_pred[indices,0])+mse(rtm_from_pred_cuda,images[indices,0])\n",
    "            loss2_2=ms_ssim_loss_fn_rtm(rtm_from_pred_cuda.reshape(-1,1,n_channel,img_size),v_pred[indices,0].reshape(-1,1,n_channel,img_size))+ms_ssim_loss_fn_rtm(rtm_from_pred_cuda.reshape(-1,1,n_channel,img_size),images[indices,0].reshape(-1,1,n_channel,img_size))\n",
    "\n",
    "\n",
    "#             loss2_1=mse(rtm_from_pred_cuda,v_pred[indices,0])+ms_ssim_loss_fn_rtm(rtm_from_pred_cuda.reshape(-1,1,n_channel,img_size),v_pred[indices,0].reshape(-1,1,n_channel,img_size))\n",
    "#             loss2_2=mse(rtm_from_pred_cuda,images[indices,0])+ms_ssim_loss_fn_rtm(rtm_from_pred_cuda.reshape(-1,1,n_channel,img_size),images[indices,0].reshape(-1,1,n_channel,img_size))\n",
    "\n",
    "#             loss1 = rf.mse_loss(v_pred, images, x_0)#尝试将他进一步拆开~~~ loss_1_1 只关于vp  loss_1_2 只关于rtm  loss_1_1可以和loss_2组合（因为他们都是关于vp的）加起来的权重跟rtm一样\n",
    "#             loss=loss1/loss1.detach().clone()+0.1*loss2/ loss2.detach().clone()\n",
    "            \n",
    "            loss1_1 = rf.mse_loss(v_pred[:,0], images[:,0], x_0[:,0])\n",
    "                                                      \n",
    "            loss1_2 = rf.mse_loss(v_pred[:,1], images[:,1], x_0[:,1])\n",
    "            \n",
    "            # 计算每个损失的梯度\n",
    "            loss1_1.backward(retain_graph=True)\n",
    "            grad1_1 = [p.grad.norm() for p in model.parameters() if p.grad is not None]\n",
    "\n",
    "            loss1_2.backward(retain_graph=True)\n",
    "            grad1_2 = [p.grad.norm() for p in model.parameters() if p.grad is not None]\n",
    "\n",
    "\n",
    "            # 计算每个任务的梯度范数\n",
    "            grad_norm1_1 = sum(grad1_1)/len(grad1_1)  # 或者用平均值/最大值等\n",
    "            grad_norm1_2 = sum(grad1_2)/len(grad1_2) \n",
    "#             grad_norm2_1 = sum(grad2_1)\n",
    "#             grad_norm2_2 = sum(grad2_2)\n",
    "\n",
    "            # 计算梯度范数的倒数作为权重\n",
    "            weight1_1 = 1.0 / (grad_norm1_1 + 1e-12)  # 加上小值避免除0\n",
    "            weight1_2 = 1.0 / (grad_norm1_2 + 1e-12)\n",
    "            weight2_1 = 5.0 / (grad_norm1_1 + 1e-12)*indices.shape[0]/batch_size\n",
    "            weight2_2 = 5.0 / (grad_norm1_1 + 1e-12)*indices.shape[0]/batch_size\n",
    "\n",
    "            # 对权重进行标准化\n",
    "            total_weight = weight1_1 + weight1_2 + weight2_1 + weight2_2\n",
    "            weight1_1 /= total_weight\n",
    "            weight1_2 /= total_weight\n",
    "            weight2_1 /= total_weight\n",
    "            weight2_2 /= total_weight\n",
    "#             print(weight1_1,weight1_2,weight2_1,weight2_2)\n",
    "            # 最终加权的损失函数\n",
    "            loss = weight1_1 * loss1_1 + weight1_2 * loss1_2/(loss1_2/loss1_1).detach().clone()+weight2_1 * loss2_1/(loss2_1/loss1_1).detach().clone() +0.01*weight2_2 * loss2_2/(loss2_2/loss1_1).detach().clone()\n",
    "            \n",
    "            \n",
    "            ## loss1_1 标签image损失 loss1_2  标签vel损失  loss2_1 预测vel合成的image与预测image的差 loss2_2表示 预测vel合成的image与真实image的差\n",
    "            ##所以 loss1_1 与 loss1_2是首先最需要优化的值（因为有真实标签） \n",
    "            ##loss2_2 是第二需要优化的（因为有真实标签，但关系更为间接） loss2_1是第三需要优化的（只是让网络内部保持一致）\n",
    "#             loss=loss1_1/loss1_1.detach().clone()+1*loss1_2/loss1_2.detach().clone()+0.5*loss2_1/loss2_1.detach().clone()+1*loss2_2/loss2_2.detach().clone()\n",
    "            epoch_loss +=(loss1_1.item()+loss1_2.item())\n",
    "        else:\n",
    "            loss1_1 = rf.mse_loss(v_pred[:,0], images[:,0], x_0[:,0])\n",
    "            loss1_2 = rf.mse_loss(v_pred[:,1], images[:,1], x_0[:,1])\n",
    "            loss=loss1_1/loss1_1.detach().clone()+1*loss1_2/loss1_2.detach().clone()\n",
    "            epoch_loss +=(loss1_1.item()+loss1_2.item())\n",
    "        num_batches += 1\n",
    "#         epoch_loss +=(loss1.item()+loss2.item())\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema.step_ema(ema_model, model)\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    loss_list.append(avg_epoch_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step()     \n",
    "    if epoch%100==0:\n",
    "\n",
    "            torch.save(model.state_dict(), os.path.join(\"models\", run_name, \"{}_ckpt.pt\".format(epoch)))\n",
    "            torch.save(model.state_dict(), os.path.join(\"models\", run_name, \"ckpt.pt\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(\"models\", run_name, f\"ckpt.pt\"))\n",
    "torch.save(ema_model.state_dict(), os.path.join(\"models\", run_name, \"ckpt_ema.pt\".format(epoch)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"models/\"+ run_name+\"_loss_{}.txt\".format(epoch),np.array(loss_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
